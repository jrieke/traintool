{"config":{"lang":["en"],"min_search_length":3,"prebuild_index":false,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Train off-the-shelf machine learning models in one line of code Try it out in Google Colab \u2022 Documentation traintool is the easiest Python library for applied machine learning . It allows you to train off-the-shelf models with minimum code: Just give your data and the model name, and traintool takes care of the rest. It combines pre-implemented models (built on top of sklearn & pytorch) with powerful utilities that get you started in seconds (automatic visualizations, experiment tracking, intelligent data preprocessing, API deployment). Alpha Release traintool is in an early alpha release. The API can and will change without notice. If you find a bug, please file an issue on Github or write me . Installation \u00b6 pip install traintool Features \u00b6 Minimum coding \u2014 traintool is designed to require as few lines of code as possible. It offers a sleek and intuitive interface that gets you started in seconds. Training a model just takes a single line: traintool . train ( \"resnet18\" , train_data , test_data , config = { \"optimizer\" : \"adam\" , \"lr\" : 0.1 }) Pre-implemented models \u2014 The heart of traintool are fully implemented and tested models \u2013 from simple classifiers to deep neural networks; built on sklearn, pytorch, or tensorflow. Here are only a few of the models you can use: \" svc \" , \" random-forest \" , \" alexnet \" , \" resnet50 \" , \" inception_v3 \" , ... Automatic visualizations & experiment tracking \u2014 traintool automatically calculates metrics, creates beautiful visualizations (in tensorboard or comet.ml ), and stores experiment data and model checkpoints \u2013 without needing a single additional line of code. Ready for your data \u2014 traintool understands numpy arrays, pytorch datasets, and files. It automatically converts and preprocesses everything based on the model you use. Instant deployment \u2014 In one line of code, you can deploy your model to a REST API that you can query from anywhere. Just call: model.deploy() Example: Image classification on MNIST \u00b6 Run this example interactively in Google Colab: import mnist import traintool # Load MNIST data as numpy train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] # Train SVM classifier svc = traintool . train ( \"svc\" , train_data = train_data , test_data = test_data ) # Train ResNet with custom hyperparameters resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" }) # Make prediction result = resnet . predict ( test_data [ 0 ][ 0 ]) print ( result [ \"predicted_class\" ]) # Deploy to REST API resnet . deploy () # Get underlying pytorch model (e.g. for custom analysis) pytorch_model = resnet . raw ()[ \"model\" ] For more information, check out the complete tutorial . Get in touch! \u00b6 You have a question on traintool, want to use it in production, or miss a feature? I'm happy to hear from you! Write me at johannes.rieke@gmail.com .","title":"About"},{"location":"#installation","text":"pip install traintool","title":"Installation"},{"location":"#features","text":"Minimum coding \u2014 traintool is designed to require as few lines of code as possible. It offers a sleek and intuitive interface that gets you started in seconds. Training a model just takes a single line: traintool . train ( \"resnet18\" , train_data , test_data , config = { \"optimizer\" : \"adam\" , \"lr\" : 0.1 }) Pre-implemented models \u2014 The heart of traintool are fully implemented and tested models \u2013 from simple classifiers to deep neural networks; built on sklearn, pytorch, or tensorflow. Here are only a few of the models you can use: \" svc \" , \" random-forest \" , \" alexnet \" , \" resnet50 \" , \" inception_v3 \" , ... Automatic visualizations & experiment tracking \u2014 traintool automatically calculates metrics, creates beautiful visualizations (in tensorboard or comet.ml ), and stores experiment data and model checkpoints \u2013 without needing a single additional line of code. Ready for your data \u2014 traintool understands numpy arrays, pytorch datasets, and files. It automatically converts and preprocesses everything based on the model you use. Instant deployment \u2014 In one line of code, you can deploy your model to a REST API that you can query from anywhere. Just call: model.deploy()","title":"Features"},{"location":"#example-image-classification-on-mnist","text":"Run this example interactively in Google Colab: import mnist import traintool # Load MNIST data as numpy train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] # Train SVM classifier svc = traintool . train ( \"svc\" , train_data = train_data , test_data = test_data ) # Train ResNet with custom hyperparameters resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" }) # Make prediction result = resnet . predict ( test_data [ 0 ][ 0 ]) print ( result [ \"predicted_class\" ]) # Deploy to REST API resnet . deploy () # Get underlying pytorch model (e.g. for custom analysis) pytorch_model = resnet . raw ()[ \"model\" ] For more information, check out the complete tutorial .","title":"Example: Image classification on MNIST"},{"location":"#get-in-touch","text":"You have a question on traintool, want to use it in production, or miss a feature? I'm happy to hear from you! Write me at johannes.rieke@gmail.com .","title":"Get in touch!"},{"location":"models/image-classification/","text":"Image classification \u00b6 Image classification models classify an image into one out of several categories or classes, based on the image content (e.g. \"cat\" or \"dog\"). Input formats \u00b6 Numpy arrays \u00b6 Each data set should be a list of two elements: The first element is a numpy array of all images of shape (number of images, color channels (1 or 3), height, width) . The second element is an array of labels (as integer indices). Example: train_images = np . zeros ( 32 , 3 , 256 , 256 ) # 32 images with 3 color channels and size 256x256 train_labels = np . zeros ( 32 , dtype = int ) traintool . train ( ... , train_data = [ train_images , train_labels ]) Files \u00b6 Image files should be arranged in one folder per class, similar to this: train +-- dogs | +-- funny-dog.jpg | +-- another-dog.png +-- cats | +-- brown-cat.png | +-- black-cat.png ... Then simply pass the directory path to the train function: traintool . train ( ... , train_data = \"./train\" ) Scikit-learn models \u00b6 These models implement simple classification algorithms that should train in a reasonable amount of time. Note that they are not GPU-accelerated so they might still take quite long with large datasets. Preprocessing: Image files are first loaded to a size of 28 x 28. All images (numpy or files) are then flattened and scaled to mean 0, standard deviation 1 (based on the train set). Config parameters: num_samples : Set the number of samples to train on. This can be used to train on a subset of the data. Defaults to None (i.e. train on all data). num_samples_to_plot : Set the number of samples to plot to tensorboard for each dataset. Defaults to 5. All other config parameters are forwarded to the constructor of the sklearn object Models: random-forest : A random forest classifier, from sklearn.ensemble.RandomForestClassifier gradient-boosting : Gradient boosting for classification, from sklearn.ensemble.GradientBoostingClassifier gaussian-process : Gaussian process classification based on Laplace approximation, from sklearn.gaussian_process.GaussianProcessClassifier logistic-regression : Logistic Regression (aka logit, MaxEnt) classifier, from sklearn.linear_model.LogisticRegression sgd : Linear classifiers (SVM, logistic regression, etc.) with SGD training, from sklearn.linear_model.SGDClassifier perceptron : A perceptron classifier, from sklearn.linear_model.Perceptron passive-aggressive : Passive aggressive classifier, from sklearn.linear_model.PassiveAggressiveClassifier gaussian-nb : Gaussian Naive Bayes, from sklearn.naive_bayes.GaussianNB k-neighbors : Classifier implementing the k-nearest neighbors vote, from sklearn.neighbors.KNeighborsClassifier mlp : Multi-layer Perceptron classifier, from sklearn.neural_network.MLPClassifier svc : C-Support Vector Classification, from sklearn.svm.SVC linear-svc : Linear Support Vector Classification, from sklearn.svm.LinearSVC decision-tree : A decision tree classifier, from sklearn.tree.DecisionTreeClassifier extra-tree : An extra-trees classifier, from sklearn.ensemble.ExtraTreesClassifier PyTorch models \u00b6 These models implement deep neural networks that can give better results on complex datasets. They are GPU-accelerated if run on a machine with a GPU. Preprocessing: All images (numpy or files) are rescaled to 256 x 256, then center-cropped to 224 x 224, MEAN STD Config parameters: num_classes : The number of classes/different output labels (and therefore number of output neurons of the network). Defaults to None, in which case it will be automatically inferred from the data. num_samples : Set the number of samples to train on. This can be used to train on a subset of the data. Defaults to None (i.e. train on all data). num_samples_to_plot : Set the number of samples to plot to tensorboard for each dataset. Defaults to 5. pretrained : Whether to use pretrained weights for the models (trained on ImageNet). Note that this requires that there are 1000 classes (the ImageNet classes). Defaults to False. Models: More information on the torchvision docs . alexnet : AlexNet model architecture from the \u201cOne weird trick\u2026\u201d paper vgg11 , vgg11_bn , vgg13 , vgg13_bn , vgg16 , vgg16_bn , vgg19 , or vgg19_bn : VGG model variants from \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d resnet18 , resnet34 , resnet50 , resnet101 , or resnet152 : ResNet model variants from \u201cDeep Residual Learning for Image Recognition\u201d squeezenet1_0 , or squeezenet1_1 : SqueezeNet model variants from the \u201cSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\u201d paper. densenet121 , densenet169 , densenet161 , or densenet201 : Densenet model variants from \u201cDensely Connected Convolutional Networks\u201d inception_v3 : Inception v3 model architecture from \u201cRethinking the Inception Architecture for Computer Vision\u201d googlenet : GoogLeNet (Inception v1) model architecture from \u201cGoing Deeper with Convolutions\u201d shufflenet_v2_x0_5 , shufflenet_v2_x1_0 , shufflenet_v2_x1_5 , or shufflenet_v2_x2_0 : ShuffleNetV2 variants, as described in \u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d mobilenet_v2 : MobileNetV2 architecture from \u201cMobileNetV2: Inverted Residuals and Linear Bottlenecks\u201d resnext50_32x4d or resnext101_32x8d : ResNeXt model variants from \u201cAggregated Residual Transformation for Deep Neural Networks\u201d wide_resnet50_2 or wide_resnet101_2 : Wide ResNet-50-2 model variants from \u201cWide Residual Networks\u201d mnasnet0_5 , mnasnet0_75 , mnasnet1_0 , or mnasnet1_3 : MNASNet variants from \u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d","title":"Image Classification"},{"location":"models/image-classification/#image-classification","text":"Image classification models classify an image into one out of several categories or classes, based on the image content (e.g. \"cat\" or \"dog\").","title":"Image classification"},{"location":"models/image-classification/#input-formats","text":"","title":"Input formats"},{"location":"models/image-classification/#numpy-arrays","text":"Each data set should be a list of two elements: The first element is a numpy array of all images of shape (number of images, color channels (1 or 3), height, width) . The second element is an array of labels (as integer indices). Example: train_images = np . zeros ( 32 , 3 , 256 , 256 ) # 32 images with 3 color channels and size 256x256 train_labels = np . zeros ( 32 , dtype = int ) traintool . train ( ... , train_data = [ train_images , train_labels ])","title":"Numpy arrays"},{"location":"models/image-classification/#files","text":"Image files should be arranged in one folder per class, similar to this: train +-- dogs | +-- funny-dog.jpg | +-- another-dog.png +-- cats | +-- brown-cat.png | +-- black-cat.png ... Then simply pass the directory path to the train function: traintool . train ( ... , train_data = \"./train\" )","title":"Files"},{"location":"models/image-classification/#scikit-learn-models","text":"These models implement simple classification algorithms that should train in a reasonable amount of time. Note that they are not GPU-accelerated so they might still take quite long with large datasets. Preprocessing: Image files are first loaded to a size of 28 x 28. All images (numpy or files) are then flattened and scaled to mean 0, standard deviation 1 (based on the train set). Config parameters: num_samples : Set the number of samples to train on. This can be used to train on a subset of the data. Defaults to None (i.e. train on all data). num_samples_to_plot : Set the number of samples to plot to tensorboard for each dataset. Defaults to 5. All other config parameters are forwarded to the constructor of the sklearn object Models: random-forest : A random forest classifier, from sklearn.ensemble.RandomForestClassifier gradient-boosting : Gradient boosting for classification, from sklearn.ensemble.GradientBoostingClassifier gaussian-process : Gaussian process classification based on Laplace approximation, from sklearn.gaussian_process.GaussianProcessClassifier logistic-regression : Logistic Regression (aka logit, MaxEnt) classifier, from sklearn.linear_model.LogisticRegression sgd : Linear classifiers (SVM, logistic regression, etc.) with SGD training, from sklearn.linear_model.SGDClassifier perceptron : A perceptron classifier, from sklearn.linear_model.Perceptron passive-aggressive : Passive aggressive classifier, from sklearn.linear_model.PassiveAggressiveClassifier gaussian-nb : Gaussian Naive Bayes, from sklearn.naive_bayes.GaussianNB k-neighbors : Classifier implementing the k-nearest neighbors vote, from sklearn.neighbors.KNeighborsClassifier mlp : Multi-layer Perceptron classifier, from sklearn.neural_network.MLPClassifier svc : C-Support Vector Classification, from sklearn.svm.SVC linear-svc : Linear Support Vector Classification, from sklearn.svm.LinearSVC decision-tree : A decision tree classifier, from sklearn.tree.DecisionTreeClassifier extra-tree : An extra-trees classifier, from sklearn.ensemble.ExtraTreesClassifier","title":"Scikit-learn models"},{"location":"models/image-classification/#pytorch-models","text":"These models implement deep neural networks that can give better results on complex datasets. They are GPU-accelerated if run on a machine with a GPU. Preprocessing: All images (numpy or files) are rescaled to 256 x 256, then center-cropped to 224 x 224, MEAN STD Config parameters: num_classes : The number of classes/different output labels (and therefore number of output neurons of the network). Defaults to None, in which case it will be automatically inferred from the data. num_samples : Set the number of samples to train on. This can be used to train on a subset of the data. Defaults to None (i.e. train on all data). num_samples_to_plot : Set the number of samples to plot to tensorboard for each dataset. Defaults to 5. pretrained : Whether to use pretrained weights for the models (trained on ImageNet). Note that this requires that there are 1000 classes (the ImageNet classes). Defaults to False. Models: More information on the torchvision docs . alexnet : AlexNet model architecture from the \u201cOne weird trick\u2026\u201d paper vgg11 , vgg11_bn , vgg13 , vgg13_bn , vgg16 , vgg16_bn , vgg19 , or vgg19_bn : VGG model variants from \u201cVery Deep Convolutional Networks For Large-Scale Image Recognition\u201d resnet18 , resnet34 , resnet50 , resnet101 , or resnet152 : ResNet model variants from \u201cDeep Residual Learning for Image Recognition\u201d squeezenet1_0 , or squeezenet1_1 : SqueezeNet model variants from the \u201cSqueezeNet: AlexNet-level accuracy with 50x fewer parameters and <0.5MB model size\u201d paper. densenet121 , densenet169 , densenet161 , or densenet201 : Densenet model variants from \u201cDensely Connected Convolutional Networks\u201d inception_v3 : Inception v3 model architecture from \u201cRethinking the Inception Architecture for Computer Vision\u201d googlenet : GoogLeNet (Inception v1) model architecture from \u201cGoing Deeper with Convolutions\u201d shufflenet_v2_x0_5 , shufflenet_v2_x1_0 , shufflenet_v2_x1_5 , or shufflenet_v2_x2_0 : ShuffleNetV2 variants, as described in \u201cShuffleNet V2: Practical Guidelines for Efficient CNN Architecture Design\u201d mobilenet_v2 : MobileNetV2 architecture from \u201cMobileNetV2: Inverted Residuals and Linear Bottlenecks\u201d resnext50_32x4d or resnext101_32x8d : ResNeXt model variants from \u201cAggregated Residual Transformation for Deep Neural Networks\u201d wide_resnet50_2 or wide_resnet101_2 : Wide ResNet-50-2 model variants from \u201cWide Residual Networks\u201d mnasnet0_5 , mnasnet0_75 , mnasnet1_0 , or mnasnet1_3 : MNASNet variants from \u201cMnasNet: Platform-Aware Neural Architecture Search for Mobile\u201d","title":"PyTorch models"},{"location":"models/object-detection/","text":"Object detection \u00b6 Coming soon!","title":"Object detection"},{"location":"models/object-detection/#object-detection","text":"Coming soon!","title":"Object detection"},{"location":"models/text-classification/","text":"Text classification \u00b6 Coming soon!","title":"Text classification"},{"location":"models/text-classification/#text-classification","text":"Coming soon!","title":"Text classification"},{"location":"tutorial/deployment/","text":"Deployment \u00b6 traintool can easily deploy your model through a REST API. This allows you to access the model from a website or application without shipping it with your code. Deployment uses FastAPI under the hood, which makes the API fully compatible with OpenAPI/Swagger and JSON Schema . Deploying a model \u00b6 To deploy a model after training or loading, simply run: model . deploy () Note that the call to deploy is blocking, i.e. it should be run in a separate script. Also, it might not work well with Jupyter notebooks. Tip By default, the API will run on 127.0.0.1 at port 8000, but you can modify this, e.g. model.deploy(host=0.0.0.0, port=8001) . Accessing the API \u00b6 To access the API, navigate your browser to http://127.0.0.1:8000/ . If everything worked out, you should see some basic information about the deployed model like below: To find out more about the API, check out the API docs at http://127.0.0.1:8000/docs . They contain information about all endpoints and required data types. Making predictions \u00b6 If you want to make a prediction with the API, you need to make a POST request to the /predict endpoint ( http://127.0.0.1:8000/predict ). The request body should look like this: { \"image\" : [[[ 0 , 0.5 , 0 , 1 ], [ 0 , 1 , 0 , 0.5 ]]] } \"image\" is a list of lists with shape color channels x height x width (here: a grayscale 4x4 image). You can easily get this list format from a numpy array with numpy.ndarray.tolist . Note that you cannot pass raw numpy arrays into the request because they are not JSON serializable. As in training, images can be RGB (3 color channels) or grayscale (1 color channel). They will be automatically preprocessed in the same way as the train data. If you used numpy images for training, make sure the image here has the same size and pixel range. If you used files, everything should be converted to the correct format automatically. Tip You can easily try out the /predict endpoint if you go to the API docs ( http://127.0.0.1:8000/docs ), click on /predict and then on the \"Try it out\" button on the right. The endpoint will return a JSON object which is very similar to the dictionary returned by model.predict(...) . Numpy arrays are again converted to lists of lists (convert back with numpy.asarray ). The JSON should look like this: { \"predicted_class\" : 2 , \"probabilities\" : [ 0.1 , 0.8 , 0.1 ], \"runtime\" : \"0:00:00.088831\" }","title":"Deployment"},{"location":"tutorial/deployment/#deployment","text":"traintool can easily deploy your model through a REST API. This allows you to access the model from a website or application without shipping it with your code. Deployment uses FastAPI under the hood, which makes the API fully compatible with OpenAPI/Swagger and JSON Schema .","title":"Deployment"},{"location":"tutorial/deployment/#deploying-a-model","text":"To deploy a model after training or loading, simply run: model . deploy () Note that the call to deploy is blocking, i.e. it should be run in a separate script. Also, it might not work well with Jupyter notebooks. Tip By default, the API will run on 127.0.0.1 at port 8000, but you can modify this, e.g. model.deploy(host=0.0.0.0, port=8001) .","title":"Deploying a model"},{"location":"tutorial/deployment/#accessing-the-api","text":"To access the API, navigate your browser to http://127.0.0.1:8000/ . If everything worked out, you should see some basic information about the deployed model like below: To find out more about the API, check out the API docs at http://127.0.0.1:8000/docs . They contain information about all endpoints and required data types.","title":"Accessing the API"},{"location":"tutorial/deployment/#making-predictions","text":"If you want to make a prediction with the API, you need to make a POST request to the /predict endpoint ( http://127.0.0.1:8000/predict ). The request body should look like this: { \"image\" : [[[ 0 , 0.5 , 0 , 1 ], [ 0 , 1 , 0 , 0.5 ]]] } \"image\" is a list of lists with shape color channels x height x width (here: a grayscale 4x4 image). You can easily get this list format from a numpy array with numpy.ndarray.tolist . Note that you cannot pass raw numpy arrays into the request because they are not JSON serializable. As in training, images can be RGB (3 color channels) or grayscale (1 color channel). They will be automatically preprocessed in the same way as the train data. If you used numpy images for training, make sure the image here has the same size and pixel range. If you used files, everything should be converted to the correct format automatically. Tip You can easily try out the /predict endpoint if you go to the API docs ( http://127.0.0.1:8000/docs ), click on /predict and then on the \"Try it out\" button on the right. The endpoint will return a JSON object which is very similar to the dictionary returned by model.predict(...) . Numpy arrays are again converted to lists of lists (convert back with numpy.asarray ). The JSON should look like this: { \"predicted_class\" : 2 , \"probabilities\" : [ 0.1 , 0.8 , 0.1 ], \"runtime\" : \"0:00:00.088831\" }","title":"Making predictions"},{"location":"tutorial/experiment-tracking/","text":"Experiment tracking \u00b6 traintool tracks common metrics automatically (e.g. accuracy on train and test set) and has different options to store and visualize them. Tensorboard \u00b6 Tensorboard is a popular visualization toolkit from Google's tensorflow framework. By default, traintool automatically stores logs for tensorboard along with the model, so that you can visualize the metrics of your experiments. To start tensorboard, run on your terminal (from the project dir): tensorboard --logdir traintool-experiments Navigate your browser to http://localhost:6006/ and you should see the tensorboard window: INSERT IMAGE HERE On the bottom left, you can select all the different runs (same names as the directories in traintool-experiments ), on the right side you can view the metrics. Comet.ml \u00b6 You can store these metrics in comet.ml , a popular platform for experiment tracking. They offer free accounts (you can sign up with your Github account), and free premium for students & academia. Once you have your account, log in to comet.ml, click on your profile in the upper right corner, go on settings and on \"Generate API Key\". Pass this API key along to the train function like this: traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , comet_config = { \"api_key\" : YOUR_API_KEY , \"project_name\" : OPTIONAL_PROJECT_NAME }) Now you can head on over to comet.ml and follow the metrics in real time!","title":"Experiment tracking"},{"location":"tutorial/experiment-tracking/#experiment-tracking","text":"traintool tracks common metrics automatically (e.g. accuracy on train and test set) and has different options to store and visualize them.","title":"Experiment tracking"},{"location":"tutorial/experiment-tracking/#tensorboard","text":"Tensorboard is a popular visualization toolkit from Google's tensorflow framework. By default, traintool automatically stores logs for tensorboard along with the model, so that you can visualize the metrics of your experiments. To start tensorboard, run on your terminal (from the project dir): tensorboard --logdir traintool-experiments Navigate your browser to http://localhost:6006/ and you should see the tensorboard window: INSERT IMAGE HERE On the bottom left, you can select all the different runs (same names as the directories in traintool-experiments ), on the right side you can view the metrics.","title":"Tensorboard"},{"location":"tutorial/experiment-tracking/#cometml","text":"You can store these metrics in comet.ml , a popular platform for experiment tracking. They offer free accounts (you can sign up with your Github account), and free premium for students & academia. Once you have your account, log in to comet.ml, click on your profile in the upper right corner, go on settings and on \"Generate API Key\". Pass this API key along to the train function like this: traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data , comet_config = { \"api_key\" : YOUR_API_KEY , \"project_name\" : OPTIONAL_PROJECT_NAME }) Now you can head on over to comet.ml and follow the metrics in real time!","title":"Comet.ml"},{"location":"tutorial/intro/","text":"Intro \u00b6 This tutorial shows you everything that traintool can do. We will train a few different models on MNIST, use automated experiment tracking, deploy the models via REST APIs, and get access to the underlying, raw models. Installation \u00b6 If you haven't installed traintool yet, now is a good time: pip install git+https://github.com/jrieke/traintool Dataset \u00b6 We will use the MNIST dataset throughout this tutorial. Just in case you never heard of it: MNIST is a popular dataset for image classification. It contains images of handwritten digits and the task is to predict which digit is shown on a given image. Below are some examples.","title":"Intro"},{"location":"tutorial/intro/#intro","text":"This tutorial shows you everything that traintool can do. We will train a few different models on MNIST, use automated experiment tracking, deploy the models via REST APIs, and get access to the underlying, raw models.","title":"Intro"},{"location":"tutorial/intro/#installation","text":"If you haven't installed traintool yet, now is a good time: pip install git+https://github.com/jrieke/traintool","title":"Installation"},{"location":"tutorial/intro/#dataset","text":"We will use the MNIST dataset throughout this tutorial. Just in case you never heard of it: MNIST is a popular dataset for image classification. It contains images of handwritten digits and the task is to predict which digit is shown on a given image. Below are some examples.","title":"Dataset"},{"location":"tutorial/quickstart/","text":"(function() { function addWidgetsRenderer() { var mimeElement = document.querySelector('script[type=\"application/vnd.jupyter.widget-view+json\"]'); var scriptElement = document.createElement('script'); var widgetRendererSrc = 'https://unpkg.com/@jupyter-widgets/html-manager@*/dist/embed-amd.js'; var widgetState; // Fallback for older version: try { widgetState = mimeElement && JSON.parse(mimeElement.innerHTML); if (widgetState && (widgetState.version_major < 2 || !widgetState.version_major)) { widgetRendererSrc = 'jupyter-js-widgets@*/dist/embed.js'; } } catch(e) {} scriptElement.src = widgetRendererSrc; document.body.appendChild(scriptElement); } document.addEventListener('DOMContentLoaded', addWidgetsRenderer); }()); Quickstart \u00b6 Welcome to traintool ! In this quickstart, we will train a few models on MNIST. This should give you a rough overview of what traintool can do. You can follow along interactively in Google Colab (a free Jupyter notebook service): We highly recommend to use Colab for this tutorial because it gives you free GPU access, which makes training much faster. Important: To enable GPU support, click on \"Runtime\" -> \"Change runtime type\", select \"GPU\" and hit \"Save\". First, let's install traintool: ! pip install - U git + https : // github . com / jrieke / traintool Next, we import traintool and load the mnist dataset (installed with traintool): import traintool import mnist train_images = mnist.train_images()[:, None] # add color dimension train_labels = mnist.train_labels() test_images = mnist.test_images()[:, None] test_labels = mnist.test_labels() print(\"Images shape:\", train_images.shape) print(\"Labels shape:\", train_labels.shape) As you can see, all data from the mnist package comes as numpy arrays. Images have the shape num samples x color channels x height x width . Note that traintool can handle numpy arrays like here as well as image files on your machine (see here). Your first model \u00b6 Let's train our first model! We will use a very simple model, a support vector classifier (called svc in traintool). Training it requires only one line of code: Note: We use the config parameter num_samples here to train only on a subset of the data to make it faster. svc = traintool . train ( \"svc\" , train_data = [ train_images , train_labels ], test_data = [ test_images , test_labels ], config = { \"num_samples\" : 500 }) That looks very simple \u2013 but under the hood, a lot of stuff happened: 1) traintool printed some general information about the experiment: Its ID, which model and configuration was used, where the model is saved and how you can load it later. 2) Then, it preprocessed the data. It automatically converted all data to the correct format and applied some light preprocessing that makes sense with this model. 3) It created and trained the model. Under the hood, traintool uses different frameworks for this step (e.g. scikit-learn or pytorch) but as a user, you don't have to worry about any of this. After training, traintool printed the resulting accuracies (should be 80-85 % here). 4) traintool automatically saved the model, console output and tensorboard logs into a time-stamped folder (see below). Making predictions \u00b6 To make a prediction with this model, simply use its predict function: svc.predict(test_images[0]) This gives you a dictionary with the predicted class and probabilities for each class. Note that for now, predict can only process a single image at a time. As the train method, it works with numpy arrays and image files (see here). Using other models \u00b6 Ok, now what if you want to train a different model? traintool makes this very easy: You only have to call the train function with a different model name \u2013 no need to rewrite the implementation or change the data just because you use a model from a different framework! Let's train a residual network ( resnet18 ), a deep neural network from pytorch (make sure to use a GPU!): resnet = traintool . train ( \"resnet18\" , train_data = [ train_images , train_labels ], test_data = [ test_images , test_labels ], config = { \"batch_size\" : 128 , \"print_every\" : 10 , \"num_epochs\" : 2 , \"num_samples\" : 10000 }) And with this simple command, you can train all models supported by traintool! See here for a list of models. As you may have noticed, we set some parameters with the config argument above. config is the central place to define hyperparameters for training. The supported hyperparameters vary from model to model \u2013 it's best to have a look at the overview page linked above. Experiment tracking \u00b6 traintool automatically keeps track of all experiments you run. Each experiment is stored in a time-stamped folder in ./traintool-experiments . Have a look at this folder now to see the experiments you ran above! (If you are in Colab, click on the folder icon on the top left). Tip: You can disable saving with save=False . Each experiment folder contains: info.yml : General information about the experiment stdout.log : The entire console output model files and possibly checkpoints (e.g. the pytorch binary model.pt for resnet18) tensorboard logs (see below) Visualizations \u00b6 traintool writes all metrics and evaluations to tensorboard , a powerful visualization platform from tensorflow. Let's start tensorboard now: If you are on a local machine, start a terminal in this dir and type tensorboard --logdir traintool-experiments . If you are on Colab, just run the cell below: %load_ext tensorboard %tensorboard -- logdir traintool - experiments / Let's see what's going on here: On the bottom left, you can select individual experiments. On the right, you should by default see scalar metrics: The loss and accuracy for train and test set. You can also click on Images at the top to see some sample images from both datasets along with classification results (use the sliders to look at different epochs!). Tip: You can also store metrics in comet.ml, see here. Other functions \u00b6 Before we end this quickstart, let's look at three other important functions: Loading: To load a saved model, just pass its ID (or directory path) to traintool.load(...) . Check out the line starting with Load via: in the console output above \u2013 it shows you directly which command to call. Deployment: traintool can easily deploy your trained model through a REST API. Simply call model.deploy() to start the server (note that this call is blocking!). More information here. Raw models: traintool models are implemented in different frameworks, e.g. scikit-learn or pytorch. You can get access to the raw models by calling model.raw() . That's it! You should now be able to start using traintool. Make sure to read the complete tutorial and documentation to learn more! Please also consider leaving a \u2b50 on our Github .","title":"Quickstart"},{"location":"tutorial/quickstart/#quickstart","text":"Welcome to traintool ! In this quickstart, we will train a few models on MNIST. This should give you a rough overview of what traintool can do. You can follow along interactively in Google Colab (a free Jupyter notebook service): We highly recommend to use Colab for this tutorial because it gives you free GPU access, which makes training much faster. Important: To enable GPU support, click on \"Runtime\" -> \"Change runtime type\", select \"GPU\" and hit \"Save\". First, let's install traintool: ! pip install - U git + https : // github . com / jrieke / traintool Next, we import traintool and load the mnist dataset (installed with traintool): import traintool import mnist train_images = mnist.train_images()[:, None] # add color dimension train_labels = mnist.train_labels() test_images = mnist.test_images()[:, None] test_labels = mnist.test_labels() print(\"Images shape:\", train_images.shape) print(\"Labels shape:\", train_labels.shape) As you can see, all data from the mnist package comes as numpy arrays. Images have the shape num samples x color channels x height x width . Note that traintool can handle numpy arrays like here as well as image files on your machine (see here).","title":"Quickstart"},{"location":"tutorial/quickstart/#your-first-model","text":"Let's train our first model! We will use a very simple model, a support vector classifier (called svc in traintool). Training it requires only one line of code: Note: We use the config parameter num_samples here to train only on a subset of the data to make it faster. svc = traintool . train ( \"svc\" , train_data = [ train_images , train_labels ], test_data = [ test_images , test_labels ], config = { \"num_samples\" : 500 }) That looks very simple \u2013 but under the hood, a lot of stuff happened: 1) traintool printed some general information about the experiment: Its ID, which model and configuration was used, where the model is saved and how you can load it later. 2) Then, it preprocessed the data. It automatically converted all data to the correct format and applied some light preprocessing that makes sense with this model. 3) It created and trained the model. Under the hood, traintool uses different frameworks for this step (e.g. scikit-learn or pytorch) but as a user, you don't have to worry about any of this. After training, traintool printed the resulting accuracies (should be 80-85 % here). 4) traintool automatically saved the model, console output and tensorboard logs into a time-stamped folder (see below).","title":"Your first model"},{"location":"tutorial/quickstart/#making-predictions","text":"To make a prediction with this model, simply use its predict function: svc.predict(test_images[0]) This gives you a dictionary with the predicted class and probabilities for each class. Note that for now, predict can only process a single image at a time. As the train method, it works with numpy arrays and image files (see here).","title":"Making predictions"},{"location":"tutorial/quickstart/#using-other-models","text":"Ok, now what if you want to train a different model? traintool makes this very easy: You only have to call the train function with a different model name \u2013 no need to rewrite the implementation or change the data just because you use a model from a different framework! Let's train a residual network ( resnet18 ), a deep neural network from pytorch (make sure to use a GPU!): resnet = traintool . train ( \"resnet18\" , train_data = [ train_images , train_labels ], test_data = [ test_images , test_labels ], config = { \"batch_size\" : 128 , \"print_every\" : 10 , \"num_epochs\" : 2 , \"num_samples\" : 10000 }) And with this simple command, you can train all models supported by traintool! See here for a list of models. As you may have noticed, we set some parameters with the config argument above. config is the central place to define hyperparameters for training. The supported hyperparameters vary from model to model \u2013 it's best to have a look at the overview page linked above.","title":"Using other models"},{"location":"tutorial/quickstart/#experiment-tracking","text":"traintool automatically keeps track of all experiments you run. Each experiment is stored in a time-stamped folder in ./traintool-experiments . Have a look at this folder now to see the experiments you ran above! (If you are in Colab, click on the folder icon on the top left). Tip: You can disable saving with save=False . Each experiment folder contains: info.yml : General information about the experiment stdout.log : The entire console output model files and possibly checkpoints (e.g. the pytorch binary model.pt for resnet18) tensorboard logs (see below)","title":"Experiment tracking"},{"location":"tutorial/quickstart/#visualizations","text":"traintool writes all metrics and evaluations to tensorboard , a powerful visualization platform from tensorflow. Let's start tensorboard now: If you are on a local machine, start a terminal in this dir and type tensorboard --logdir traintool-experiments . If you are on Colab, just run the cell below: %load_ext tensorboard %tensorboard -- logdir traintool - experiments / Let's see what's going on here: On the bottom left, you can select individual experiments. On the right, you should by default see scalar metrics: The loss and accuracy for train and test set. You can also click on Images at the top to see some sample images from both datasets along with classification results (use the sliders to look at different epochs!). Tip: You can also store metrics in comet.ml, see here.","title":"Visualizations"},{"location":"tutorial/quickstart/#other-functions","text":"Before we end this quickstart, let's look at three other important functions: Loading: To load a saved model, just pass its ID (or directory path) to traintool.load(...) . Check out the line starting with Load via: in the console output above \u2013 it shows you directly which command to call. Deployment: traintool can easily deploy your trained model through a REST API. Simply call model.deploy() to start the server (note that this call is blocking!). More information here. Raw models: traintool models are implemented in different frameworks, e.g. scikit-learn or pytorch. You can get access to the raw models by calling model.raw() . That's it! You should now be able to start using traintool. Make sure to read the complete tutorial and documentation to learn more! Please also consider leaving a \u2b50 on our Github .","title":"Other functions"},{"location":"tutorial/raw-models/","text":"Accessing raw models \u00b6 traintool is built on top of powerful machine learning libraries like scikit-learn or p ytorch. After training, it gives you full access to the raw models with: model . raw () This returns a dict of all underlying model objects. It usually contains the model itself ( model.raw()[\"model\"] ) but might also contain some other objects, e.g. data scalers ( model.raw()[\"scaler\"] ).","title":"Accessing raw models"},{"location":"tutorial/raw-models/#accessing-raw-models","text":"traintool is built on top of powerful machine learning libraries like scikit-learn or p ytorch. After training, it gives you full access to the raw models with: model . raw () This returns a dict of all underlying model objects. It usually contains the model itself ( model.raw()[\"model\"] ) but might also contain some other objects, e.g. data scalers ( model.raw()[\"scaler\"] ).","title":"Accessing raw models"},{"location":"tutorial/training/","text":"Training and Prediction \u00b6 Your first model \u00b6 As a first example, we'll train a very simple model: A Support Vector Machine or SVM. We will use the image classification dataset MNIST throughout this tutorial, so let's load it now (the mnist package was installed along with traintool): import mnist train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] Tip The code above loads the data as numpy arrays but traintool can also deal with files and pytorch datasets (see here). More data formats will be added soon. Training the SVM classifier is very simple now: import traintool svc = traintool . train ( \"svc\" , train_data = train_data , test_data = test_data ) That's it! traintool will take care of reading and converting the data, applying some light preprocessing, training and saving the model, and tracking all metrics. It will also print out the final loss and accuracy (the test accuracy should be around XX % here). Making predictions \u00b6 Of course, you can do predictions with the trained model. Let's run it on an image of the test set: pred = svc . predict ( test_data [ 0 ][ 0 ]) print ( \"Predicted:\" , pred [ \"predicted_class\" ], \" - Is:\" , test_data [ 1 ][ 0 ]) This should print out the predicted class and the ground truth. Note that pred is a dictionary with the predicted class ( pred[\"predicted_class\"] ) and the probabilities for each class ( pred[\"probabilities\"] ). Tip Again, we use a numpy array for the test image here but traintool can also handle pytorch tensors and files. You can even pass in a whole batch of images (e.g. test_data[0][0:2] ). Using other models \u00b6 Now, let's check a more advanced model. We will train a Residual Network (ResNet), a modern deep neural network. Usually, training this model instead of an SVM would require you to use an advanced framework like pytorch or tensorflow and rewrite most of your codebase. With traintool, it's as simple replacing the model name in the train method: resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data ) And this syntax stays the same for every other model that traintool supports! This makes it really easy to compare a bunch of different models on your dataset and see what performs best. Custom hyperparameters \u00b6 In machine learning, most models have some hyperparameters that control the training process (e.g. the learning rate). traintool uses sensible defaults specific to each model, but gives you the flexibility to fully customize everything. First, let's find out which hyperparameters the model supports and what their defaults are: print ( traintool . default_hyperparameters ( \"resnet\" )) This should print out a dictionary of hyperparameters and defaults. Now, we want to change the learning rate and use a different optimizer. To do this, simply pass a config dict to the train method: config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } better_resnet = traintool . train ( \"resnet\" , config = config , train_data = train_data , test_data = test_data ) Saving and loading models \u00b6 There are two options to save a model to disk. Either use the save method after training like this: model = traintool . train ( \"...\" ) model . save ( \"path/to/dir\" ) Or you can specify an output directory directly during training. This makes sense for long-running processes, so you don't lose the whole progress in case your machine is interrupted: model = traintool . train ( \"...\" , save = \"path/to/dir\" ) In both cases, loading a model works via: model = traintool . load ( \"path/to/dir\" ) <!-- \u00b6 This tutorial should show you everything to get started with traintool. We'll train and use a few different models on MNIST. Installation \u00b6 In the terminal, type: pip install git+https://github.com/jrieke/traintool Note that traintool requires Python 3. Data \u00b6 We will use the image classification dataset MNIST throughout this tutorial. It contains images of handwritten digits, that need to be classified according to the digit 0-9. To load it, start a Python console and enter: import mnist train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] The mnist package should have been installed along with traintool. It loads the images and labels as numpy arrays. Tip Besides numpy arrays, traintool can also handle pytorch datasets and files. More data formats will be added soon. Training \u00b6 Train a Support Vector Machine : import traintool svc = traintool . train ( \"svc\" , train_data = train_data , test_data = test_data ) Or train a Residual Network : resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data ) Or train any other model that traintool supports! It's as simple as changing the model name \u2013 no need to learn a new framework or change your entire code base. traintool makes it super easy to compare different models. Prediction \u00b6 Run an image from the test set through the model: pred = svc . predict ( test_data [ 0 ][ 0 ]) print ( \"Predicted:\" , pred [ \"predicted_class\" ], \" - Is:\" , test_data [ 1 ][ 0 ]) pred is a dictionary with the predicted class ( pred[\"predicted_class\"] ) and the probabilities for each class ( pred[\"probabilities\"] ) Hyperparameters \u00b6 Every model comes with sensible defaults for the hyperparameters. You can get these defaults via: print ( traintool . default_hyperparameters ( \"resnet\" )) To change hyperparameters, pass a config dict to the train method: config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } better_resnet = traintool . train ( \"resnet\" , config = config , train_data = train_data , test_data = test_data )","title":"Training and Prediction"},{"location":"tutorial/training/#training-and-prediction","text":"","title":"Training and Prediction"},{"location":"tutorial/training/#your-first-model","text":"As a first example, we'll train a very simple model: A Support Vector Machine or SVM. We will use the image classification dataset MNIST throughout this tutorial, so let's load it now (the mnist package was installed along with traintool): import mnist train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] Tip The code above loads the data as numpy arrays but traintool can also deal with files and pytorch datasets (see here). More data formats will be added soon. Training the SVM classifier is very simple now: import traintool svc = traintool . train ( \"svc\" , train_data = train_data , test_data = test_data ) That's it! traintool will take care of reading and converting the data, applying some light preprocessing, training and saving the model, and tracking all metrics. It will also print out the final loss and accuracy (the test accuracy should be around XX % here).","title":"Your first model"},{"location":"tutorial/training/#making-predictions","text":"Of course, you can do predictions with the trained model. Let's run it on an image of the test set: pred = svc . predict ( test_data [ 0 ][ 0 ]) print ( \"Predicted:\" , pred [ \"predicted_class\" ], \" - Is:\" , test_data [ 1 ][ 0 ]) This should print out the predicted class and the ground truth. Note that pred is a dictionary with the predicted class ( pred[\"predicted_class\"] ) and the probabilities for each class ( pred[\"probabilities\"] ). Tip Again, we use a numpy array for the test image here but traintool can also handle pytorch tensors and files. You can even pass in a whole batch of images (e.g. test_data[0][0:2] ).","title":"Making predictions"},{"location":"tutorial/training/#using-other-models","text":"Now, let's check a more advanced model. We will train a Residual Network (ResNet), a modern deep neural network. Usually, training this model instead of an SVM would require you to use an advanced framework like pytorch or tensorflow and rewrite most of your codebase. With traintool, it's as simple replacing the model name in the train method: resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data ) And this syntax stays the same for every other model that traintool supports! This makes it really easy to compare a bunch of different models on your dataset and see what performs best.","title":"Using other models"},{"location":"tutorial/training/#custom-hyperparameters","text":"In machine learning, most models have some hyperparameters that control the training process (e.g. the learning rate). traintool uses sensible defaults specific to each model, but gives you the flexibility to fully customize everything. First, let's find out which hyperparameters the model supports and what their defaults are: print ( traintool . default_hyperparameters ( \"resnet\" )) This should print out a dictionary of hyperparameters and defaults. Now, we want to change the learning rate and use a different optimizer. To do this, simply pass a config dict to the train method: config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } better_resnet = traintool . train ( \"resnet\" , config = config , train_data = train_data , test_data = test_data )","title":"Custom hyperparameters"},{"location":"tutorial/training/#saving-and-loading-models","text":"There are two options to save a model to disk. Either use the save method after training like this: model = traintool . train ( \"...\" ) model . save ( \"path/to/dir\" ) Or you can specify an output directory directly during training. This makes sense for long-running processes, so you don't lose the whole progress in case your machine is interrupted: model = traintool . train ( \"...\" , save = \"path/to/dir\" ) In both cases, loading a model works via: model = traintool . load ( \"path/to/dir\" )","title":"Saving and loading models"},{"location":"tutorial/training/#-","text":"This tutorial should show you everything to get started with traintool. We'll train and use a few different models on MNIST.","title":"&lt;!--"},{"location":"tutorial/training/#installation","text":"In the terminal, type: pip install git+https://github.com/jrieke/traintool Note that traintool requires Python 3.","title":"Installation"},{"location":"tutorial/training/#data","text":"We will use the image classification dataset MNIST throughout this tutorial. It contains images of handwritten digits, that need to be classified according to the digit 0-9. To load it, start a Python console and enter: import mnist train_data = [ mnist . train_images (), mnist . train_labels ()] test_data = [ mnist . test_images (), mnist . test_labels ()] The mnist package should have been installed along with traintool. It loads the images and labels as numpy arrays. Tip Besides numpy arrays, traintool can also handle pytorch datasets and files. More data formats will be added soon.","title":"Data"},{"location":"tutorial/training/#training","text":"Train a Support Vector Machine : import traintool svc = traintool . train ( \"svc\" , train_data = train_data , test_data = test_data ) Or train a Residual Network : resnet = traintool . train ( \"resnet\" , train_data = train_data , test_data = test_data ) Or train any other model that traintool supports! It's as simple as changing the model name \u2013 no need to learn a new framework or change your entire code base. traintool makes it super easy to compare different models.","title":"Training"},{"location":"tutorial/training/#prediction","text":"Run an image from the test set through the model: pred = svc . predict ( test_data [ 0 ][ 0 ]) print ( \"Predicted:\" , pred [ \"predicted_class\" ], \" - Is:\" , test_data [ 1 ][ 0 ]) pred is a dictionary with the predicted class ( pred[\"predicted_class\"] ) and the probabilities for each class ( pred[\"probabilities\"] )","title":"Prediction"},{"location":"tutorial/training/#hyperparameters","text":"Every model comes with sensible defaults for the hyperparameters. You can get these defaults via: print ( traintool . default_hyperparameters ( \"resnet\" )) To change hyperparameters, pass a config dict to the train method: config = { \"lr\" : 0.1 , \"optimizer\" : \"adam\" } better_resnet = traintool . train ( \"resnet\" , config = config , train_data = train_data , test_data = test_data )","title":"Hyperparameters"}]}